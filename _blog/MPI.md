---
title: "MPI"
collection: blog
type: "blog"
date: 2025-11-18
excerpt: 'Distributed memory coding.'
location: "Sanya, China"
---

最近要写mpi代码, 于是学习一些基本的mpi

## 基本通信概念与构建原理

### mpi是一种进程间通信协议

首先，为什么使用进程这种程度的抽象，而不是thread，因为进程是程序运行的最小的完备抽象。进程为程序提供了独立的内存抽象（虚拟地址空间）以及执行资源（cgroups）等，因此需要显式通信的程序最基本的层次就是进程。

mpi定义了一些标准的api和协议，用于进程间相互通信。

对于一个mpi程序，其启动方式通常为mpirun/mpiexec。mpirun将会启动守护进程，并通过守护进程启动（fork出）用户定义数量的进程，并为每个进程提供合适的环境变量。

```mermaid
graph TD
A[mpiexec 启动] --> B[资源发现和分配]
B --> C[进程启动管理器]
C --> 
C --> E[进程1] 
C --> F[进程2]
C --> G[进程3]

H[通信层初始化] --> I[建立进程间连接]
I --> D
I --> E
I --> F
I --> G

J[环境设置] --> K[设置MPI环境变量]
K --> D
K --> E
K --> F
K --> G
```

在mpirun启动程序后，这些进程的表现是独立的，在第一次调用mpi init函数后，守护进程负责创建mpi通信器，它记录了所有进程间的进程号和id的映射关系。守护进程通过通信器对所有管理的进程两两握手。也就是mpi init是一次同步操作。

```mermaid
graph TD
    A[mpirun启动] --> B[“创建独立进程<br>每个进程有独立内存空间”]
    B --> C[“执行MPI_Init之前代码<br>进程间完全独立”]
    C --> D[“调用MPI_Init<br>关键转折点”]
    D --> E[“建立通信基础设施<br>创建MPI_COMM_WORLD”]
    E --> F[“MPI环境完全就绪<br>通信器可用”]
```

```mermaid
sequenceDiagram
    participant P0 as 进程0
    participant P1 as 进程1  
    participant P2 as 进程2
    participant P3 as 进程3
    
    Note over P0,P3: MPI_Init之前: 完全独立
    
    P0->>P0: 执行初始化前代码
    P1->>P1: 执行初始化前代码
    P2->>P2: 执行初始化前代码  
    P3->>P3: 执行初始化前代码
    
    Note over P0,P3: MPI_Init调用: 建立连接和同步
    
    P0->>P1: 握手
    P0->>P2: 握手
    P0->>P3: 握手
    P1->>P2: 握手
    P1->>P3: 握手
    P2->>P3: 握手
    
    Note over P0,P3: 所有进程等待同步完成
    
    P0->>P0: 继续执行后续代码
    P1->>P1: 继续执行后续代码
    P2->>P2: 继续执行后续代码
    P3->>P3: 继续执行后续代码
```

在通讯组的工作完成后，需要调用mpi finalize注销通信器，清理无关变量，然后所有进程理应销毁。

对于一个mpi程序而言，它遵守的是spmd编程范式，也就是说所有程序都相同，只能通过自身rank来判断执行何种指令。

对于一个程序而言，其通信拓扑可以任意复杂。mpi协议允许在一个程序内创建多个通讯器，从而达到对分工协作的目的。然而每次创建通信器都有可能触发一次同步操作，在每个通信组中，进程的rank是完全独立的，这些rank就是同步的结果。新的通信器将为管理的进程赋予独立的从0开始的rank编号。

## 基本mpi概念

对于进程相互通信，最基本的操作就是发送和接收。

对于发送和接受消息，都需要buffer，它充当寄信和守信的信箱，而mpi通讯器就是邮递员。这块buffer完全就是普通的内存，既可以是栈上的也可以是堆上的。

调用mpi send/recv，通信器将会监控和管理buffer，完成对buffer内数据的读写。

mpi除了最基本的同步send/recv，还提供了异步的操作，合适的使用可以隐藏延迟。

除此外，还有一些通用的全局操作，包括bcast，all gather， all reduce等，实现了高性能的全局通信。

## 高级特性 (未整理, ai generated)

MPI进程拓扑

核心概念

进程拓扑为MPI进程提供结构化的通信关系，让通信模式更贴近问题的几何结构，而不是简单的线性rank排列。

主要行为

笛卡尔拓扑（网格拓扑）：

· 将进程排列成多维网格，每个进程有明确的坐标位置
· 自动计算物理邻居关系（上下左右、前后等方向）
· 支持周期性边界，形成环形连接
· 可以创建行、列等子通信器，在子网格内进行集体操作
· 进程通过坐标而非rank来定位，通信更直观

图拓扑：

· 定义任意的进程连接关系，适用于不规则通信模式
· 每个进程有特定的邻居集合，不要求规则的几何结构
· 适合建模复杂的依赖关系，如稀疏矩阵计算、图算法

核心价值

· 通信局部性：利用空间局部性优化通信模式
· 邻居发现：自动管理复杂的连接关系
· 代码可读性：用几何概念而非抽象rank来表达通信

MPI单边通信

核心概念

单边通信允许进程直接访问其他进程的内存空间，类似于共享内存编程模型，但运行在分布式内存系统上。

主要行为

三种基本操作：

· Put操作：将本地数据写入远程进程的内存
· Get操作：从远程进程的内存读取数据到本地
· Accumulate操作：对远程内存执行原子操作（如累加）

同步模式：

· Fence同步：所有进程在窗口操作前后同步，类似全局栅栏
· 主动目标同步：数据拥有者主动暴露内存，访问者按需访问
· 被动目标同步：使用锁机制保护远程内存访问

窗口对象：

· 定义可供远程访问的内存区域
· 指定起始地址、大小和对齐要求
· 管理访问权限和一致性

核心价值

· 编程灵活性：解耦数据通信与进程同步
· 性能优化：支持通信与计算重叠
· 算法简化：某些算法用单边通信表达更自然

MPI动态进程管理

核心概念

允许在运行时创建和管理MPI进程，支持更灵活的并行执行模式。

主要行为

进程生成：

· 父进程可以在运行时动态生成子进程
· 指定要启动的可执行文件和参数
· 自动建立父子进程间的通信连接
· 处理进程生成失败的情况

进程连接：

· 独立启动的MPI进程可以通过端口互相连接
· 一个进程打开端口并发布地址
· 其他进程连接该端口形成新的通信器
· 支持服务端-客户端模式的并行应用

交互通信器：

· 管理不同进程组之间的通信
· 提供进程rank在不同组间的映射
· 支持合并通信器形成统一进程组

核心价值

· 运行时灵活性：根据负载动态调整进程数量
· 容错支持：替换故障进程或增加计算资源
· 工作流集成：连接不同并行程序形成计算流水线
· 资源优化：按需分配计算资源，提高利用率

综合应用场景

科学计算模拟

使用网格拓扑表达物理空间的离散化，利用单边通信实现邻域数据交换，根据需要动态调整计算网格的分辨率。

大数据处理

主进程管理任务调度，动态生成工作进程处理数据分片，工作进程通过单边通信直接汇总结果到主进程。

多物理场耦合

不同物理场使用不同的进程拓扑，通过动态进程连接实现场之间的数据交换，每个场可以独立调整并行策略。

这些高级特性使MPI从简单的进程间通信库演变为支持复杂并行模式的全功能并行编程环境。